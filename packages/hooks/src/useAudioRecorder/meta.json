{
  "$schema": "https://raw.githubusercontent.com/sseuniverse/sse-hooks/refs/heads/main/schema/meta.json",
  "name": "use-audio-recorder",
  "type": "registry:hook",
  "title": "useAudioRecorder",
  "description": "Supported audio MIME types for recording.",
  "dependencies": [
    "react"
  ],
  "registryDependencies": [
    "with-defaults"
  ],
  "file": {
    "content": "type AudioMimeType =\n  | \"audio/webm\"\n  | \"audio/webm;codecs=opus\"\n  | \"audio/webm;codecs=vorbis\"\n  | \"audio/ogg\"\n  | \"audio/ogg;codecs=opus\"\n  | \"audio/ogg;codecs=vorbis\"\n  | \"application/ogg\"\n  | \"audio/mp4\"\n  | \"audio/mp4;codecs=mp4a.40.2\"\n  | \"audio/aac\"\n  | \"audio/x-m4a\"\n  | \"audio/mpeg\"\n  | \"audio/mp3\"\n  | \"audio/wav\"\n  | \"audio/x-wav\"\n  | \"audio/wave\"\n  | \"audio/flac\"\n  | \"audio/3gpp\"\n  | \"audio/3gpp2\";\n\nexport interface UseAudioRecorderOptions {\n  audioBitsPerSecond?: number;\n\n  mimeType?: AudioMimeType;\n\n  timeslice?: number;\n\n  enableAnalysis?: boolean;\n\n  fftSize?: number;\n}\n\nexport interface AudioAnalysisData {\n  frequencyData: Uint8Array;\n\n  timeData: Uint8Array;\n\n  volume: number;\n}\n\nexport interface UseAudioRecorderReturn {\n  isSupported: boolean;\n\n  isRecording: boolean;\n\n  isPaused: boolean;\n\n  stream: MediaStream | null;\n\n  mediaRecorder: MediaRecorder | null;\n\n  audioBlob: Blob | null;\n\n  audioUrl: string | null;\n\n  duration: number;\n\n  error: string | null;\n\n  analysisData: AudioAnalysisData | null;\n\n  startRecording: () => Promise<void>;\n\n  stopRecording: () => void;\n\n  pauseRecording: () => void;\n\n  resumeRecording: () => void;\n\n  clearRecording: () => void;\n\n  downloadRecording: (filename?: string) => void;\n}\n\nimport { useState, useEffect, useRef, useCallback } from \"react\";\nimport { withDefaults } from \"./with-defaults\";\n\nexport const useAudioRecorder = (\n  options: UseAudioRecorderOptions = {},\n): UseAudioRecorderReturn => {\n  const { audioBitsPerSecond, mimeType, timeslice, enableAnalysis, fftSize } =\n    withDefaults<UseAudioRecorderOptions>(options, {\n      audioBitsPerSecond: 128000,\n      mimeType: \"audio/webm\",\n      enableAnalysis: false,\n      fftSize: 2048,\n    });\n\n  const [isRecording, setIsRecording] = useState(false);\n  const [isPaused, setIsPaused] = useState(false);\n  const [stream, setStream] = useState<MediaStream | null>(null);\n  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(\n    null,\n  );\n  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);\n  const [audioUrl, setAudioUrl] = useState<string | null>(null);\n  const [duration, setDuration] = useState(0);\n  const [error, setError] = useState<string | null>(null);\n  const [analysisData, setAnalysisData] = useState<AudioAnalysisData | null>(\n    null,\n  );\n\n  const chunksRef = useRef<Blob[]>([]);\n  const startTimeRef = useRef<number>(0);\n  const pausedTimeRef = useRef<number>(0);\n  const intervalRef = useRef<NodeJS.Timeout | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);\n  const animationFrameRef = useRef<number | null>(null);\n\n  const isSupported =\n    typeof navigator !== \"undefined\" &&\n    !!navigator.mediaDevices &&\n    !!navigator.mediaDevices.getUserMedia &&\n    !!window.MediaRecorder;\n\n  const updateDuration = useCallback(() => {\n    if (startTimeRef.current) {\n      const elapsed = Date.now() - startTimeRef.current - pausedTimeRef.current;\n      setDuration(Math.floor(elapsed / 1000));\n    }\n  }, []);\n\n  const analyzeAudio = useCallback(() => {\n    if (!analyserRef.current || !enableAnalysis) return;\n\n    const frequencyData = new Uint8Array(analyserRef.current.frequencyBinCount);\n    const timeData = new Uint8Array(analyserRef.current.fftSize);\n\n    analyserRef.current.getByteFrequencyData(frequencyData);\n    analyserRef.current.getByteTimeDomainData(timeData);\n\n    let sum = 0;\n    for (let i = 0; i < timeData.length; i++) {\n      const sample = ((timeData[i] ?? 0) - 128) / 128;\n      sum += sample * sample;\n    }\n    const volume = Math.sqrt(sum / timeData.length);\n\n    setAnalysisData({\n      frequencyData: frequencyData.slice(),\n      timeData: timeData.slice(),\n      volume,\n    });\n\n    if (isRecording && !isPaused) {\n      animationFrameRef.current = requestAnimationFrame(analyzeAudio);\n    }\n  }, [isRecording, isPaused, enableAnalysis]);\n\n  const setupAudioAnalysis = useCallback(\n    (mediaStream: MediaStream) => {\n      if (!enableAnalysis) return;\n\n      try {\n        audioContextRef.current = new (\n          window.AudioContext || (window as any).webkitAudioContext\n        )();\n        analyserRef.current = audioContextRef.current.createAnalyser();\n        sourceRef.current =\n          audioContextRef.current.createMediaStreamSource(mediaStream);\n\n        analyserRef.current.fftSize = fftSize;\n        analyserRef.current.smoothingTimeConstant = 0.8;\n\n        sourceRef.current.connect(analyserRef.current);\n\n        analyzeAudio();\n      } catch (err) {\n        console.warn(\"Failed to setup audio analysis:\", err);\n      }\n    },\n    [enableAnalysis, fftSize, analyzeAudio],\n  );\n\n  const startRecording = useCallback(async () => {\n    if (!isSupported) {\n      setError(\"Audio recording is not supported in this browser\");\n      return;\n    }\n\n    try {\n      setError(null);\n      const mediaStream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true,\n        },\n      });\n\n      setStream(mediaStream);\n      setupAudioAnalysis(mediaStream);\n\n      const recorder = new MediaRecorder(mediaStream, {\n        audioBitsPerSecond,\n        mimeType: MediaRecorder.isTypeSupported(mimeType)\n          ? mimeType\n          : \"audio/webm\",\n      });\n\n      chunksRef.current = [];\n\n      recorder.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          chunksRef.current.push(event.data);\n        }\n      };\n\n      recorder.onstop = () => {\n        const blob = new Blob(chunksRef.current, { type: recorder.mimeType });\n        setAudioBlob(blob);\n        setAudioUrl(URL.createObjectURL(blob));\n        setIsRecording(false);\n        setIsPaused(false);\n\n        if (intervalRef.current) {\n          clearInterval(intervalRef.current);\n          intervalRef.current = null;\n        }\n\n        if (animationFrameRef.current) {\n          cancelAnimationFrame(animationFrameRef.current);\n          animationFrameRef.current = null;\n        }\n      };\n\n      recorder.onpause = () => {\n        setIsPaused(true);\n        pausedTimeRef.current += Date.now() - startTimeRef.current;\n        if (animationFrameRef.current) {\n          cancelAnimationFrame(animationFrameRef.current);\n          animationFrameRef.current = null;\n        }\n      };\n\n      recorder.onresume = () => {\n        setIsPaused(false);\n        startTimeRef.current = Date.now();\n        if (enableAnalysis) {\n          analyzeAudio();\n        }\n      };\n\n      recorder.onerror = (event) => {\n        setError(`Recording error: ${event.error?.message || \"Unknown error\"}`);\n        setIsRecording(false);\n        setIsPaused(false);\n      };\n\n      setMediaRecorder(recorder);\n      recorder.start(timeslice);\n      setIsRecording(true);\n      startTimeRef.current = Date.now();\n      pausedTimeRef.current = 0;\n      setDuration(0);\n\n      intervalRef.current = setInterval(updateDuration, 1000);\n    } catch (err) {\n      const errorMessage =\n        err instanceof Error ? err.message : \"Failed to start recording\";\n      setError(errorMessage);\n    }\n  }, [\n    isSupported,\n    audioBitsPerSecond,\n    mimeType,\n    timeslice,\n    setupAudioAnalysis,\n    updateDuration,\n    enableAnalysis,\n    analyzeAudio,\n  ]);\n\n  const stopRecording = useCallback(() => {\n    if (mediaRecorder && mediaRecorder.state !== \"inactive\") {\n      mediaRecorder.stop();\n    }\n\n    if (stream) {\n      stream.getTracks().forEach((track) => track.stop());\n      setStream(null);\n    }\n\n    if (audioContextRef.current) {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n  }, [mediaRecorder, stream]);\n\n  const pauseRecording = useCallback(() => {\n    if (mediaRecorder && mediaRecorder.state === \"recording\") {\n      mediaRecorder.pause();\n    }\n  }, [mediaRecorder]);\n\n  const resumeRecording = useCallback(() => {\n    if (mediaRecorder && mediaRecorder.state === \"paused\") {\n      mediaRecorder.resume();\n    }\n  }, [mediaRecorder]);\n\n  const clearRecording = useCallback(() => {\n    if (audioUrl) {\n      URL.revokeObjectURL(audioUrl);\n    }\n    setAudioBlob(null);\n    setAudioUrl(null);\n    setDuration(0);\n    setAnalysisData(null);\n    setError(null);\n  }, [audioUrl]);\n\n  const downloadRecording = useCallback(\n    (filename = \"recording.webm\") => {\n      if (!audioUrl) return;\n\n      const link = document.createElement(\"a\");\n      link.href = audioUrl;\n      link.download = filename;\n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n    },\n    [audioUrl],\n  );\n\n  useEffect(() => {\n    return () => {\n      if (intervalRef.current) {\n        clearInterval(intervalRef.current);\n      }\n      if (animationFrameRef.current) {\n        cancelAnimationFrame(animationFrameRef.current);\n      }\n      if (stream) {\n        stream.getTracks().forEach((track) => track.stop());\n      }\n      if (audioContextRef.current) {\n        audioContextRef.current.close();\n      }\n      if (audioUrl) {\n        URL.revokeObjectURL(audioUrl);\n      }\n    };\n  }, [stream, audioUrl]);\n\n  return {\n    isSupported,\n    isRecording,\n    isPaused,\n    stream,\n    mediaRecorder,\n    audioBlob,\n    audioUrl,\n    duration,\n    error,\n    analysisData,\n    startRecording,\n    stopRecording,\n    pauseRecording,\n    resumeRecording,\n    clearRecording,\n    downloadRecording,\n  };\n};\n",
    "js": "import { useState, useEffect, useRef, useCallback } from \"react\";\nimport { withDefaults } from \"./with-defaults\";\nexport const useAudioRecorder = (options = {}) => {\n    const { audioBitsPerSecond, mimeType, timeslice, enableAnalysis, fftSize } = withDefaults(options, {\n        audioBitsPerSecond: 128000,\n        mimeType: \"audio/webm\",\n        enableAnalysis: false,\n        fftSize: 2048,\n    });\n    const [isRecording, setIsRecording] = useState(false);\n    const [isPaused, setIsPaused] = useState(false);\n    const [stream, setStream] = useState(null);\n    const [mediaRecorder, setMediaRecorder] = useState(null);\n    const [audioBlob, setAudioBlob] = useState(null);\n    const [audioUrl, setAudioUrl] = useState(null);\n    const [duration, setDuration] = useState(0);\n    const [error, setError] = useState(null);\n    const [analysisData, setAnalysisData] = useState(null);\n    const chunksRef = useRef([]);\n    const startTimeRef = useRef(0);\n    const pausedTimeRef = useRef(0);\n    const intervalRef = useRef(null);\n    const audioContextRef = useRef(null);\n    const analyserRef = useRef(null);\n    const sourceRef = useRef(null);\n    const animationFrameRef = useRef(null);\n    const isSupported = typeof navigator !== \"undefined\" &&\n        !!navigator.mediaDevices &&\n        !!navigator.mediaDevices.getUserMedia &&\n        !!window.MediaRecorder;\n    const updateDuration = useCallback(() => {\n        if (startTimeRef.current) {\n            const elapsed = Date.now() - startTimeRef.current - pausedTimeRef.current;\n            setDuration(Math.floor(elapsed / 1000));\n        }\n    }, []);\n    const analyzeAudio = useCallback(() => {\n        if (!analyserRef.current || !enableAnalysis)\n            return;\n        const frequencyData = new Uint8Array(analyserRef.current.frequencyBinCount);\n        const timeData = new Uint8Array(analyserRef.current.fftSize);\n        analyserRef.current.getByteFrequencyData(frequencyData);\n        analyserRef.current.getByteTimeDomainData(timeData);\n        let sum = 0;\n        for (let i = 0; i < timeData.length; i++) {\n            const sample = ((timeData[i] ?? 0) - 128) / 128;\n            sum += sample * sample;\n        }\n        const volume = Math.sqrt(sum / timeData.length);\n        setAnalysisData({\n            frequencyData: frequencyData.slice(),\n            timeData: timeData.slice(),\n            volume,\n        });\n        if (isRecording && !isPaused) {\n            animationFrameRef.current = requestAnimationFrame(analyzeAudio);\n        }\n    }, [isRecording, isPaused, enableAnalysis]);\n    const setupAudioAnalysis = useCallback((mediaStream) => {\n        if (!enableAnalysis)\n            return;\n        try {\n            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n            analyserRef.current = audioContextRef.current.createAnalyser();\n            sourceRef.current =\n                audioContextRef.current.createMediaStreamSource(mediaStream);\n            analyserRef.current.fftSize = fftSize;\n            analyserRef.current.smoothingTimeConstant = 0.8;\n            sourceRef.current.connect(analyserRef.current);\n            analyzeAudio();\n        }\n        catch (err) {\n            console.warn(\"Failed to setup audio analysis:\", err);\n        }\n    }, [enableAnalysis, fftSize, analyzeAudio]);\n    const startRecording = useCallback(async () => {\n        if (!isSupported) {\n            setError(\"Audio recording is not supported in this browser\");\n            return;\n        }\n        try {\n            setError(null);\n            const mediaStream = await navigator.mediaDevices.getUserMedia({\n                audio: {\n                    echoCancellation: true,\n                    noiseSuppression: true,\n                    autoGainControl: true,\n                },\n            });\n            setStream(mediaStream);\n            setupAudioAnalysis(mediaStream);\n            const recorder = new MediaRecorder(mediaStream, {\n                audioBitsPerSecond,\n                mimeType: MediaRecorder.isTypeSupported(mimeType)\n                    ? mimeType\n                    : \"audio/webm\",\n            });\n            chunksRef.current = [];\n            recorder.ondataavailable = (event) => {\n                if (event.data.size > 0) {\n                    chunksRef.current.push(event.data);\n                }\n            };\n            recorder.onstop = () => {\n                const blob = new Blob(chunksRef.current, { type: recorder.mimeType });\n                setAudioBlob(blob);\n                setAudioUrl(URL.createObjectURL(blob));\n                setIsRecording(false);\n                setIsPaused(false);\n                if (intervalRef.current) {\n                    clearInterval(intervalRef.current);\n                    intervalRef.current = null;\n                }\n                if (animationFrameRef.current) {\n                    cancelAnimationFrame(animationFrameRef.current);\n                    animationFrameRef.current = null;\n                }\n            };\n            recorder.onpause = () => {\n                setIsPaused(true);\n                pausedTimeRef.current += Date.now() - startTimeRef.current;\n                if (animationFrameRef.current) {\n                    cancelAnimationFrame(animationFrameRef.current);\n                    animationFrameRef.current = null;\n                }\n            };\n            recorder.onresume = () => {\n                setIsPaused(false);\n                startTimeRef.current = Date.now();\n                if (enableAnalysis) {\n                    analyzeAudio();\n                }\n            };\n            recorder.onerror = (event) => {\n                setError(`Recording error: ${event.error?.message || \"Unknown error\"}`);\n                setIsRecording(false);\n                setIsPaused(false);\n            };\n            setMediaRecorder(recorder);\n            recorder.start(timeslice);\n            setIsRecording(true);\n            startTimeRef.current = Date.now();\n            pausedTimeRef.current = 0;\n            setDuration(0);\n            intervalRef.current = setInterval(updateDuration, 1000);\n        }\n        catch (err) {\n            const errorMessage = err instanceof Error ? err.message : \"Failed to start recording\";\n            setError(errorMessage);\n        }\n    }, [\n        isSupported,\n        audioBitsPerSecond,\n        mimeType,\n        timeslice,\n        setupAudioAnalysis,\n        updateDuration,\n        enableAnalysis,\n        analyzeAudio,\n    ]);\n    const stopRecording = useCallback(() => {\n        if (mediaRecorder && mediaRecorder.state !== \"inactive\") {\n            mediaRecorder.stop();\n        }\n        if (stream) {\n            stream.getTracks().forEach((track) => track.stop());\n            setStream(null);\n        }\n        if (audioContextRef.current) {\n            audioContextRef.current.close();\n            audioContextRef.current = null;\n        }\n    }, [mediaRecorder, stream]);\n    const pauseRecording = useCallback(() => {\n        if (mediaRecorder && mediaRecorder.state === \"recording\") {\n            mediaRecorder.pause();\n        }\n    }, [mediaRecorder]);\n    const resumeRecording = useCallback(() => {\n        if (mediaRecorder && mediaRecorder.state === \"paused\") {\n            mediaRecorder.resume();\n        }\n    }, [mediaRecorder]);\n    const clearRecording = useCallback(() => {\n        if (audioUrl) {\n            URL.revokeObjectURL(audioUrl);\n        }\n        setAudioBlob(null);\n        setAudioUrl(null);\n        setDuration(0);\n        setAnalysisData(null);\n        setError(null);\n    }, [audioUrl]);\n    const downloadRecording = useCallback((filename = \"recording.webm\") => {\n        if (!audioUrl)\n            return;\n        const link = document.createElement(\"a\");\n        link.href = audioUrl;\n        link.download = filename;\n        document.body.appendChild(link);\n        link.click();\n        document.body.removeChild(link);\n    }, [audioUrl]);\n    useEffect(() => {\n        return () => {\n            if (intervalRef.current) {\n                clearInterval(intervalRef.current);\n            }\n            if (animationFrameRef.current) {\n                cancelAnimationFrame(animationFrameRef.current);\n            }\n            if (stream) {\n                stream.getTracks().forEach((track) => track.stop());\n            }\n            if (audioContextRef.current) {\n                audioContextRef.current.close();\n            }\n            if (audioUrl) {\n                URL.revokeObjectURL(audioUrl);\n            }\n        };\n    }, [stream, audioUrl]);\n    return {\n        isSupported,\n        isRecording,\n        isPaused,\n        stream,\n        mediaRecorder,\n        audioBlob,\n        audioUrl,\n        duration,\n        error,\n        analysisData,\n        startRecording,\n        stopRecording,\n        pauseRecording,\n        resumeRecording,\n        clearRecording,\n        downloadRecording,\n    };\n};"
  }
}